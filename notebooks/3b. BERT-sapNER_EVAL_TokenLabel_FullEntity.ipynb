{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS TYPE:\n",
    "# label_type = 'da_only' \n",
    "label_type = 'da_sa'\n",
    "    \n",
    "# TRUE-PRED LABELS:    \n",
    "# filename = '2021-03-22_01-22-44_true_pred.csv' - retrained model\n",
    "filename = '2021-03-18_02-35-03_true_pred.csv'    # v0\n",
    "# filename = '2021-03-21_14-02-50_01-23_sa_true_pred.csv'\n",
    "# filename = '2021-03-22_01-22-44_true_pred.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LOAD True_Pred_Inference data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA:\n",
    "BASE_FOLDER = 'models_inference_true_pred/'\n",
    "# filename = '2021-03-22_01-22-44_true_pred.csv'\n",
    "        \n",
    "data = pd.read_csv(BASE_FOLDER+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')  \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[:10]\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_shrt = filename[:19]\n",
    "filename_shrt\n",
    "model_name = filename_shrt\n",
    "filename_shrt, model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) True_Labels: 'y_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df\n",
    "df_true = df_true.drop(['Tokenpred_labels'], axis=1)\n",
    "df_true = df_true.drop(['Labelpred_labels'], axis=1)\n",
    "df_true = df_true[['Sentence', 'Tokentrue_labels', 'Labeltrue_labels']]\n",
    "\n",
    "df_true = df_true.rename(columns={'Sentence': 'Sentence', 'Tokentrue_labels': 'Word', 'Labeltrue_labels':'Tag'})\n",
    "# df_true.columns={'Sentence', 'Word', 'Tag'}\n",
    "df_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'y_true' to list: 'tkn_lbl_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn_lbl_true = df_true.values.tolist()\n",
    "tkn_lbl_true[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Pred_Labels: 'y_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df\n",
    "df_pred = df_pred.drop(['Tokentrue_labels'], axis=1)\n",
    "df_pred = df_pred.drop(['Labeltrue_labels'], axis=1)\n",
    "df_pred = df_pred[['Sentence', 'Tokenpred_labels', 'Labelpred_labels']]\n",
    "df_pred = df_pred.rename(columns={'Sentence': 'Sentence', 'Tokenpred_labels': 'Word', 'Labelpred_labels':'Tag'})\n",
    "# df_pred.columns={'Sentence', 'Word', 'Tag'}\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAVE Predicted Inference to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_FOLDER = 'models_inference_predictions/'\n",
    "file_path_to_a = PRED_FOLDER+model_name+\"_inference_predictions.csv\"\n",
    "df_pred.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'y_pred' to list: 'tkn_lbl_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn_lbl_pred = df_pred.values.tolist()\n",
    "tkn_lbl_pred[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('verify labels and adjust if necessary (uncomment and run code below)')\n",
    "stop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------\n",
    "# uncomment and run code below if tag adjustemt is neccesary\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# line = []\n",
    "# temp_str = []\n",
    "\n",
    "# for line in tkn_lbl_pred:\n",
    "#     new_line = []\n",
    "#     new_line.append(line[0])\n",
    "#     new_line.append(line[1])\n",
    "#     if line[2] == 'B-PROD':\n",
    "#         new_line.append('I-PROD')\n",
    "#     elif line[2] == 'I-PROD':\n",
    "#         new_line.append('B-PROD')\n",
    "#     else:\n",
    "#         new_line.append('O')\n",
    "        \n",
    "#     temp_str.append(new_line)\n",
    "    \n",
    "# tkn_lbl_pred = temp_str\n",
    "# tkn_lbl_pred[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tkn_lbl_pred[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Get Classification Report METRICS at TOKEN/LABEL Level \n",
    "# (y_true vs y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [] \n",
    "y_true = []\n",
    "\n",
    "for i in tkn_lbl_pred:\n",
    "    if i[2] == 'B-PROD':\n",
    "        y_pred.append(0)\n",
    "    elif i[2] == 'I-PROD':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(2)\n",
    "    \n",
    "for i in tkn_lbl_true:\n",
    "    if i[2] == 'B-PROD':\n",
    "        y_true.append(0)\n",
    "    elif i[2] == 'I-PROD':\n",
    "        y_true.append(1)\n",
    "    else:\n",
    "        y_true.append(2)\n",
    "        \n",
    "target_names = ['B-PROD', 'I-PROD', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr = classification_report(y_true, y_pred, target_names=target_names, digits=6)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '2021-03-18_02-35-03_true_pred.csv'\n",
    "modelname = filename[:19]\n",
    "modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FOLDER = 'models_saved/'\n",
    "import os\n",
    "\n",
    "file = os.path.join(MODELS_FOLDER, modelname+'_eval_metrics')\n",
    "with open(file, \"a\") as writer:\n",
    "    writer.write(\"\\n\\n\") \n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write(\"\\nc) TOKEN/LABEL LEVEL Evaluation Metrics: \") \n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(cr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3) Get Full-Entities from 'y_true' and 'y_pred':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Define function to Get entities from token/label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNIT TESTING:\n",
    "# for i in tkn_lbl[:2]:\n",
    "#         print(i[0])\n",
    "#         print(i[1])\n",
    "#         print(i[2])\n",
    "#         print(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNIT TESTING:\n",
    "# for i in tkn_lbl_true[:2]:\n",
    "#     if i[2] == 'I':\n",
    "#         print(i[0])\n",
    "#         print(i[1])\n",
    "#         print(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_from_token_label_list(tkn_lbl):\n",
    "    prev_lbl = 'O'\n",
    "    entity = ''\n",
    "    entity_list = []\n",
    "    sentence_entity = []\n",
    "    entity_list2 = []\n",
    "    space = ' '\n",
    "\n",
    "    # tkn_lbl = [['sa', 'B-PROD']]\n",
    "\n",
    "    for i in tkn_lbl:\n",
    "        if i[2] == 'B-PROD':\n",
    "            if prev_lbl == 'O' or prev_lbl == 'I-PROD':\n",
    "                if entity != '':\n",
    "                    entity_list.append(entity)   # append previous entity, understand it is completed\n",
    "                    sentence_entity.append(i[0])\n",
    "                    sentence_entity.append(entity)\n",
    "                    entity_list2.append(sentence_entity)\n",
    "                    sentence_entity = []\n",
    "                    entity = ''\n",
    "\n",
    "                tkn = i[1].replace('##','')\n",
    "                entity = tkn\n",
    "                prev_lbl = 'B-PROD'\n",
    "\n",
    "            elif prev_lbl == 'B-PROD':\n",
    "                entity_list.append(entity)   # append previous entity, understand it is completed\n",
    "                sentence_entity.append(i[0])\n",
    "                sentence_entity.append(entity)\n",
    "                entity_list2.append(sentence_entity)\n",
    "                sentence_entity = []\n",
    "                entity = ''\n",
    "                \n",
    "                tkn = i[1].replace('##','')\n",
    "                entity = tkn\n",
    "                prev_lbl = 'B-PROD'         \n",
    "\n",
    "        elif i[2] == 'I-PROD':\n",
    "            if prev_lbl == 'B-PROD':\n",
    "                tkn = i[1].replace('##','')\n",
    "                entity = entity + space\n",
    "                entity = entity + tkn\n",
    "                prev_lbl = 'I-PROD'\n",
    "\n",
    "            elif prev_lbl == 'I-PROD':\n",
    "                if '##' in i[1]:\n",
    "                    tkn = i[1].replace('##','')\n",
    "                    entity = entity + tkn    \n",
    "                    prev_lbl = 'I-PROD'\n",
    "                elif '##' not in i[1]:\n",
    "                    tkn = i[1].replace('##','')\n",
    "                    entity = entity + space\n",
    "                    entity = entity + tkn    \n",
    "                    prev_lbl = 'I-PROD'\n",
    "                    \n",
    "            elif prev_lbl == 'O':\n",
    "                if entity != '':\n",
    "                    entity_list.append(entity)\n",
    "                    sentence_entity.append(i[0])\n",
    "                    sentence_entity.append(entity)\n",
    "                    entity_list2.append(sentence_entity)\n",
    "                    sentence_entity = []                    \n",
    "                    entity = ''\n",
    "\n",
    "                tkn = i[1].replace('##','')\n",
    "                entity = entity + tkn \n",
    "                prev_lbl = 'I-PROD'\n",
    "\n",
    "        elif i[2] == 'O':\n",
    "            if prev_lbl == 'B-PROD' or prev_lbl == 'I-PROD':\n",
    "                entity_list.append(entity)\n",
    "                sentence_entity.append(i[0])\n",
    "                sentence_entity.append(entity)\n",
    "                entity_list2.append(sentence_entity)\n",
    "                sentence_entity = []                \n",
    "                entity = ''\n",
    "                prev_lbl = 'O'\n",
    "            elif prev_lbl == 'O':\n",
    "                prev_lbl = 'O'\n",
    "\n",
    "    if entity != '':\n",
    "        entity_list.append(entity)\n",
    "        sentence_entity.append(i[0])\n",
    "        sentence_entity.append(entity)\n",
    "        entity_list2.append(sentence_entity)\n",
    "        sentence_entity = []        \n",
    "\n",
    "    return entity_list, entity_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Get entities from 'y_true' (True Labels): 'entity_list_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Entity Listjk\n",
    "entity_list_true, entity_list2_true = get_entities_from_token_label_list(tkn_lbl_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list2_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total TRUE Entities: ')\n",
    "print(len(entity_list_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Get entities from 'y_pred' (Predicted Labels): 'entity_list_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn_lbl_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list_pred, entity_list2_pred = get_entities_from_token_label_list(tkn_lbl_pred)\n",
    "print('Total PRED Entities: ')\n",
    "print(len(entity_list_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_list_pred[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Get \"SAP-Products\" List: 'sap_ent_prod_lwr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 1) LOAD SAP-PRODUCT_ENTITIES:\n",
    "# -------------------------------------------------------------------------\n",
    "PRODUCTS_FOLDER = \"sap-products/\"\n",
    "\n",
    "if label_type == 'da_only': \n",
    "    sap_products_file = \"prod_full_sap-L1_v2.csv\"\n",
    "elif label_type == 'da_sa': \n",
    "    sap_products_file = \"prod_full_sap-L1_v2_inclSA_v1.csv\"\n",
    "\n",
    "sap_ent_prod =[]\n",
    "fileObject = open(PRODUCTS_FOLDER+sap_products_file, \"r\")\n",
    "sap_ent_prod = fileObject.read()\n",
    "sap_ent_prod = sap_ent_prod.split('\\n')\n",
    "# sap_ent_prod\n",
    "\n",
    "# Convert to lower case:\n",
    "sap_ent_prod_lwr = []\n",
    "for p in sap_ent_prod:\n",
    "    p = p.replace('\\ufeff','')\n",
    "    sap_ent_prod_lwr.append(p.lower())\n",
    "\n",
    "sap_ent_prod_lwr = sorted(set(sap_ent_prod_lwr))\n",
    "  \n",
    "print('SAP Products loaded: ')\n",
    "print(len(sap_ent_prod_lwr))  \n",
    "  \n",
    "# print(sap_ent_prod_lwr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Get true_positive and false_positive from 'y_pred': 'true_predicted_entities', 'false_predicted_entities'\n",
    "by checking predicted entities that exist or not in the sap_product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predicted_entities = []\n",
    "false_predicted_entities = []\n",
    "\n",
    "\n",
    "for i in entity_list_pred:\n",
    "    if i in sap_ent_prod_lwr:\n",
    "        true_predicted_entities.append(i)\n",
    "    else:\n",
    "        false_predicted_entities.append(i)\n",
    "        \n",
    "print('Number of True Predicted Entities: ', len(true_predicted_entities))\n",
    "print('Number of False Predicted Entities: ', len(false_predicted_entities))\n",
    "print('Total Predicted Entities: ', len(true_predicted_entities) + len(false_predicted_entities))\n",
    "print('Total True Entities: ', len(entity_list_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = len(true_predicted_entities) / len(entity_list_true)\n",
    "print('Model Accuracy: ', Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positives:\n",
    "TP=len(true_predicted_entities)\n",
    "#False Positives:\n",
    "FP=len(false_predicted_entities)\n",
    "#False Negatives:\n",
    "FN=len(entity_list_true)-len(true_predicted_entities)\n",
    "\n",
    "TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision= TP/(TP+FP):\n",
    "precision = TP/(TP+FP)\n",
    "print('Precision = ', precision)\n",
    "\n",
    "# Recall= TP/(TP+FN)\n",
    "recall = TP/(TP+FN)\n",
    "print('Recall: ', recall)\n",
    "\n",
    "# f1-score = 2 * (Precision*Recall) / (Precision + Recall)\n",
    "f1 = 2 * (precision*recall) / (precision + recall)\n",
    "print('f1-score: ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE evaluation metrics to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(MODELS_FOLDER, modelname+'_eval_metrics')\n",
    "with open(file, \"a\") as writer:\n",
    "    writer.write(\"\\n\") \n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write(\"\\nd) FULL-ENTITY LEVEL Evaluation Metrics: \") \n",
    "    writer.write(\"\\n\")  \n",
    "    writer.write('\\nNumber of True Predicted Entities: ') \n",
    "    writer.write(str(len(true_predicted_entities)))\n",
    "    writer.write('\\nNumber of False Predicted Entities: ') \n",
    "    writer.write(str(len(false_predicted_entities)))\n",
    "    writer.write('\\nTotal Predicted Entities: ') \n",
    "    tot_pred_ent = str(len(true_predicted_entities) + len(false_predicted_entities))\n",
    "    writer.write(tot_pred_ent)\n",
    "    writer.write('\\nTotal True Entities: ') \n",
    "    writer.write(str(len(entity_list_true)))\n",
    "    writer.write('\\nPrecision = ') \n",
    "    writer.write(str(precision))\n",
    "    writer.write('\\nRecall: ')\n",
    "    writer.write(str(recall))\n",
    "    writer.write('\\nf1-score: ') \n",
    "    writer.write(str(f1))      \n",
    "    writer.write('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 'true_pred_entities' and 'false_pred_ent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_predicted_entities = sorted(true_predicted_entities)\n",
    "true_predicted_entities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_predicted_entities = sorted(false_predicted_entities)\n",
    "false_predicted_entities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Produce Wordcloud from True Positives and False positives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Define function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordcloud_from_entity_list(entity_list,true_or_false):\n",
    "    \n",
    "    from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Entity List to String\n",
    "    ents_strg = ''\n",
    "    for i in entity_list:\n",
    "        ent = i.replace(' ','_')\n",
    "        ents_strg = ents_strg + ' ' + ent\n",
    "        \n",
    "    # Create and generate a word cloud image:\n",
    "    wordcloud = WordCloud().generate(ents_strg)\n",
    "    \n",
    "    # lower max_font_size, change the maximum number of word and lighten the background:\n",
    "    wordcloud = WordCloud(max_font_size=200, max_words=350, background_color=\"white\").generate(ents_strg)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the image in the img folder:\n",
    "    # wordcloud.to_file(\"wordcloud_sapner_tds_836_1.png\")\n",
    "    wordcloud.to_file(filename_shrt+'_'+true_or_false+\"_wordcloud.png\")\n",
    "    \n",
    "    return\n",
    "    \n",
    "# print(ents_strg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Get True Positive Entities Wordcloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud_from_entity_list(entity_list_true,'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Get False Positive Entities Wordcloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud_from_entity_list(false_predicted_entities,'false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Get Count by Entities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Define function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ent_list2_to_entity_count(ent_list):\n",
    "    ent_list_df = pd.DataFrame(ent_list)\n",
    "#     ent_list_df = ent_list_df.rename(columns={ent_list_df.columns[0]: 'Sentence_Token'})\n",
    "    ent_list_df = ent_list_df.rename(columns={ent_list_df.columns[0]: 'Tag'})\n",
    "    \n",
    "    tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "    tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "\n",
    "    columnsTitles = ['Tag', 'Count']\n",
    "    tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "\n",
    "    tag_n_df\n",
    "\n",
    "    return ent_list_df, tag_n_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_file(filename, df, sufix):\n",
    "    FOLDER = 'models_inference_true_pred/'\n",
    "    name = filename[:19]+'_'+sufix\n",
    "    \n",
    "    file_path_to_a = 'models_inference_true_pred/'+name\n",
    "    df.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Entity count from TRUE LABELS ('y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EL_TL, df_EC_TL = from_ent_list2_to_entity_count(entity_list_true)\n",
    "df_EC_TL[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_file(filename, df_EC_TL, 'EC_TL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Entity count from TRUE PREDICTIONS ('y_pred_true'= true_predicted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EL_PT, df_EC_PT = from_ent_list2_to_entity_count(true_predicted_entities)\n",
    "df_EC_PT[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_file(filename, df_EC_PT, 'EC_PT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Entity count from FALSE PREDICTIONS ('y_pred_false'= false_predicted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EL_PF, df_EC_PF = from_ent_list2_to_entity_count(false_predicted_entities)\n",
    "df_EC_PF[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_file(filename, df_EC_PF, 'EC_PF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------- END OF CODE -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_type_counter(ent_list2):\n",
    "    \n",
    "    ent_list_df = pd.DataFrame(ent_list2)\n",
    "#     ent_list_df.head()\n",
    "    \n",
    "    ent_list_df.columns={'Sentence_Token', 'Tag'}\n",
    "#     ent_list_df\n",
    "    \n",
    "    ent_list_df_sap = ent_list_df[ent_list_df.Tag.str.contains(\"sap\")]\n",
    "#     ent_list_df_sap\n",
    "\n",
    "    ent_list_df = ent_list_df_sap\n",
    "    tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "    tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "    \n",
    "    columnsTitles = ['Filename', 'Tag', 'Count']\n",
    "    tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "\n",
    "    \n",
    "    return tag_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entity_type_counter(entity_list2_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_sap = []\n",
    "\n",
    "for line in entity_list2_true:\n",
    "    i = line[1]\n",
    "    if i[:3] == \"sap\":\n",
    "        ent_list_sap.append(line)\n",
    "        \n",
    "ent_list_sap[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = from_ent_list2_to_entity_count(entity_list_true)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_n_df = df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "\n",
    "columnsTitles = ['Tag', 'Count']\n",
    "tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "\n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df = pd.DataFrame(ent_list_sap)\n",
    "ent_list_df = ent_list_df.rename(columns={ent_list_df.columns[0]: 'Sentence_Token'})\n",
    "ent_list_df = ent_list_df.rename(columns={ent_list_df.columns[1]: 'Tag'})\n",
    "\n",
    "ent_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "\n",
    "columnsTitles = ['Filename', 'Tag', 'Count']\n",
    "tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "\n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df = pd.DataFrame(entity_list2_true)\n",
    "#     ent_list_df.head()\n",
    "    \n",
    "ent_list_df.columns={'Sentence_Token', 'Tag'}\n",
    "#     ent_list_df\n",
    "\n",
    "ent_list_df_sap = ent_list_df[ent_list_df.Tag.str.contains(\"sap\")]\n",
    "#     ent_list_df_sap\n",
    "\n",
    "ent_list_df = ent_list_df_sap\n",
    "tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTitles = {}'Filename', 'Tag', 'Count'\n",
    "tag_n_df = tag_n_df.columns={columns=columnsTitles\n",
    "\n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Count True Entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_entity_count = get_entity_type_counter(entity_list2_true)\n",
    "\n",
    "true_entity_count[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO FILE:\n",
    "\n",
    "# filename = \n",
    "# file_path_to_a = \"tagged_entities/Entity_Count_\"+filename[4:]\n",
    "# tag_n_df.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Count False predicted entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get false_predicted_entities2\n",
    "\n",
    "counter = 1\n",
    "false_predicted_entities2 = []\n",
    "\n",
    "for i in false_predicted_entities:\n",
    "    line=[]\n",
    "    line.append(counter)\n",
    "    line.append(i)\n",
    "    false_predicted_entities2.append(line)\n",
    "    counter = counter + 1\n",
    "    \n",
    "false_predicted_entities2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_entity_count = get_entity_type_counter(false_predicted_entities2)\n",
    "\n",
    "false_entity_count[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO FILE:\n",
    "\n",
    "# filename = \n",
    "# file_path_to_a = \"tagged_entities/Entity_Count_\"+filename[4:]\n",
    "# tag_n_df.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------- END OF CODE ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 'Entities per sentence' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent_list_df = pd.DataFrame(entity_list2, columns={'Sentence', 'Tag'})\n",
    "ent_list_df = pd.DataFrame(entity_list2)\n",
    "# ent_list_df['Counter'] = 1\n",
    "ent_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df.columns={'Sentence_Token', 'Tag'}\n",
    "ent_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df_sap = ent_list_df[ent_list_df.Tag.str.contains(\"sap\")]\n",
    "ent_list_df_sap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO FILE:\n",
    "file_path_to_a = \"tagged_entities/Sentce_Token_Tag_\"+filename[4:]\n",
    "ent_list_df.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 'Tag counter' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df = ent_list_df_sap\n",
    "tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "tag_n_df['Filename'] = filename \n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTitles = ['Filename', 'Tag', 'Count']\n",
    "\n",
    "tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "tag_n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TO FILE:\n",
    "file_path_to_a = \"tagged_entities/Entity_Count_\"+filename[4:]\n",
    "tag_n_df.to_csv(file_path_to_a, sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tag counter in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_n_l = tag_n_df.values.tolist()\n",
    "tag_n_l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tag_n_l:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final function: 'from_bio_file_to_entities_count_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'scw_01-23_sa_v6.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_bio_file_to_entities_count_df(base_folder, filename):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv(base_folder+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')  \n",
    "    \n",
    "    # move data to list object\n",
    "    tkn_lbl_2 = data.values.tolist()\n",
    "    \n",
    "    # Get Entities list and Entities per Sentence:\n",
    "    entity_list, entity_list2 = get_entities_from_token_label_list(tkn_lbl_2)\n",
    "    \n",
    "    # Get 'Entities per sentence' dataframe\n",
    "    ent_list_df = pd.DataFrame(entity_list2, columns={'Sentence', 'Tag'})\n",
    "    ent_list_df['Counter'] = 1\n",
    "    \n",
    "    # Get 'Tag counter' dataframe\n",
    "    tag_n_df = ent_list_df.groupby( [ \"Tag\"] ).size().to_frame(name = 'Count').reset_index()\n",
    "    tag_n_df = tag_n_df.sort_values(['Count', 'Tag'], ascending=False)\n",
    "    tag_n_df['Filename'] = filename \n",
    "    # Re-order columns:\n",
    "    columnsTitles = ['Filename', 'Tag', 'Count']\n",
    "    tag_n_df = tag_n_df.reindex(columns=columnsTitles)\n",
    "    \n",
    "    # Get Tag counter in list\n",
    "    tag_n_l = tag_n_df.values.tolist()\n",
    "    \n",
    "    \n",
    "    return tag_n_l\n",
    "\n",
    "# EXECUTION:\n",
    "base_folder = 'training-datasets/'\n",
    "filename = filename\n",
    "\n",
    "entity_list_count = from_bio_file_to_entities_count_df(base_folder, filename)\n",
    "entity_list_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Plot 'TAG' Groupby.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ent_list_df.groupby(by='Tag').agg('count')\n",
    "df = df.sort_values(by=['Sentence_Token'], ascending=False)\n",
    "ent_count_top30_df = df.head(30)\n",
    "ent_count_top30_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(300,200))\n",
    "ent_count_top30_df.plot.bar()\n",
    "plt.xticks(rotation=50)\n",
    "plt.xlabel(\"Entities\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tags = ent_list_df.groupby(\"Tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "Tags.size().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=50)\n",
    "plt.xlabel(\"Country of Origin\")\n",
    "plt.ylabel(\"Number of Wines\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Generate Entities' Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity List to String\n",
    "ents_strg = ''\n",
    "for i in entity_list:\n",
    "    ent = i.replace(' ','_')\n",
    "    ents_strg = ents_strg + ' ' + ent\n",
    "    \n",
    "print(ents_strg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(ents_strg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated image:\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower max_font_size, change the maximum number of word and lighten the background:\n",
    "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(ents_strg)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image in the img folder:\n",
    "wordcloud.to_file(\"wordcloud_sapner_tds_836_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(A=[5,3,5,6], C=[\"sap hana\",\"sap cloud platform\",\"hana\", \"cloud connector\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.C.str.contains(\"sap\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
