{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_FOLDER = \"corp_wiki_texts/ejecucion3/\"\n",
    "\n",
    "BASE_FOLDER = \"corp_wiki_annotated/\"\n",
    "\n",
    "# BASE_FOLDER = \"training-datasets/\"\n",
    "\n",
    "# !ls = \"{BASE_FOLDER}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import packages and set the working directory\n",
    "Change “/mydir” to your desired working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"corp_wiki_texts/ejecucion3/\")\n",
    "\n",
    "os.chdir(\"corp_wiki_annotated/\")\n",
    "\n",
    "# os.chdir(\"training-datasets/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Use glob to match the pattern ‘csv’\n",
    "Match the pattern (‘csv’) and save the list of file names in the ‘all_filenames’ variable. You can check out this link to learn more about regular expression matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = np.arange(220,273)\n",
    "file_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) add files by name string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) add files by name string\n",
    "all_filenames = []\n",
    "\n",
    "file_number = np.arange(220,273)\n",
    "\n",
    "for n in file_number:\n",
    "    file_name = \"corp-wiki-\"+str(n)+\"-annotated_sentences.csv\"\n",
    "    all_filenames.append(file_name)\n",
    "    \n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # b) add files specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # b) add files specifically\n",
    "\n",
    "# all_filenames = []\n",
    "\n",
    "# file_name = \"scw_01_23_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_24-49_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_50_99_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_100_149_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "    \n",
    "# all_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combine all files in the list and export as CSV\n",
    "Use pandas to concatenate all files in the list and export as CSV. The output file is named “combined_csv.csv” located in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "\n",
    "# #export to csv\n",
    "# TARGET_FOLDER = 'training-datasets/'\n",
    "# filename = 'scw_24_49_da.csv'\n",
    "# pathfilename = str(TARGET_FOLDER+filename)\n",
    "\n",
    "# combined_csv.to_csv(pathfilename, index=False, encoding='utf-8-sig')\n",
    "# combined_csv.to_csv( \"scw_24_49_da.csv\", index=False, encoding='utf-8-sig')\n",
    "combined_csv.to_csv('scw_220_272_da.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding = ‘utf-8-sig’ is added to overcome the issue when exporting ‘Non-English’ languages.\n",
    "\n",
    "And…it’s done!\n",
    "\n",
    "This article was inspired by my actual everyday problem, and the coding structure is from a discussion on stackoverflow. The completed script for this how-to is documented on GitHub.\n",
    "\n",
    "Thank you for reading. Please give it a try, have fun and let me know your feedback!\n",
    "\n",
    "If you like what I did, consider following me on GitHub, Medium, and Twitter. Make sure to star it on GitHub :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
