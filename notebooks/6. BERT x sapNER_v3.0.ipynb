{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN & SAVE / LOAD & RETRAIN BERT-NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads a BIO annotated dataset and does all the data preparation required for BERT-NER model training.\n",
    "It can be also used to load a trained datamodel in order to perform further training.\n",
    "\n",
    "\n",
    "input parameters:\n",
    "- filename_sa => annotated dataset to be used as 'supervised annotation'\n",
    "- filename_da => annotated dataset to be used as 'distant annotation'\n",
    "- training_source => defines what file will be used for training. Possible values: 'sa' or 'da'.\n",
    "- validation_source => defines what file will be used for validation. Possible values: 'sa' or 'da'.\n",
    "- save_model => defines whether the model checkpoint will be saved in a local folder. Possible values: 'yes' or 'no'.\n",
    "- MODEL_SOURCE => defines whether the model will be loaded from Transformers library, or loaded from a saved model. \n",
    "Possible values: 'Transformers' or 'Saved_model'. IF 'saved_models' it will be required to enter parameter 'selected_model'= modelname.checkpoint'\n",
    "\n",
    "output:\n",
    "- model.checkpoint file\n",
    "- hyperparameters file\n",
    "- evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set execution parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTION PARAMETERS:\n",
    "\n",
    "#-----------------------------\n",
    "# base folder:\n",
    "#-----------------------------\n",
    "base_folder = 'training-datasets/'\n",
    "\n",
    "\n",
    "#-----------------------------\n",
    "# dataset source files:\n",
    "#-----------------------------\n",
    "filename_sa = 'scw_01-23_sa_v6.csv'\n",
    "\n",
    "\n",
    "# filename_da = '2021-03-21_14-02-50_01-272_INFER_PL1.csv'\n",
    "# filename_da = 'scw_01_23_da.csv'\n",
    "# filename_da = 'scw_24_49_da.csv'\n",
    "# filename_da = 'scw_50_99_da.csv'\n",
    "# filename_da = 'scw_100_149_da.csv'\n",
    "# filename_da = 'scw_1-149_220-272_da.csv'\n",
    "# filename_da = 'scw_nhve_1-149_220-272_da.csv'\n",
    "# filename_da = 'scw_220_272_da.csv'\n",
    "filename_da = '2021-03-22_01-22-44_nhve_scw_220_272_INFER.csv'\n",
    "\n",
    "#-----------------------------\n",
    "# select datasources for current execution:\n",
    "#-----------------------------\n",
    "training_source = 'sa'\n",
    "validation_source = 'da'\n",
    "\n",
    "#-----------------------------\n",
    "# SAVE MODEL \n",
    "#-----------------------------\n",
    "save_model = 'no'\n",
    "# save_model = 'yes'\n",
    "\n",
    "#-----------------------------\n",
    "# TRAINING PARAMETERS\n",
    "#-----------------------------\n",
    "max_len = 256   # Max length:\n",
    "bs = 16         # Batch size: 2, 4, 8, 16\n",
    "batch_num = bs  # Batch Size:\n",
    "test_size = 0.3 # Validation/Test Split:\n",
    "lr = 5e-5       # Learning rate: 1e-5, 2e-5, 3e-5, 5e-5 \n",
    "eps = 1e-8      # EPS\n",
    "epochs = 3     # Epochs: 2,3,4,5\n",
    "\n",
    "#-----------------------------\n",
    "# Set Finetunning depth:\n",
    "#-----------------------------\n",
    "FULL_FINETUNING = True   # True: fine tuning all the layers \n",
    "# FULL_FINETUNNING = False # False: only fine tuning the classifier layers\n",
    "\n",
    "#-----------------------------\n",
    "# MODEL TRAIN CODE VERSION: \n",
    "#-----------------------------\n",
    "# train_code = 'OLD_CODE'\n",
    "train_code = 'NEW_CODE'\n",
    "\n",
    "#-----------------------------\n",
    "# SET MODEL SOURCE\n",
    "#-----------------------------\n",
    "MODEL_SOURCE = 'Transformers'\n",
    "selected_model = ''\n",
    "\n",
    "# MODEL_SOURCE = 'Saved_model'\n",
    "# selected_model = '2021-03-21_14-02-50.checkpoint'\n",
    "\n",
    "#-----------------------------\n",
    "# TRAIN MODEL:\n",
    "#-----------------------------\n",
    "TRAIN_MODEL = 'yes'\n",
    "# TRAIN_MODEL = 'no'\n",
    "\n",
    "#-----------------------------\n",
    "# GET TRAINING DATA\n",
    "#-----------------------------\n",
    "get_training_data = 'yes'\n",
    "# get_training_data = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case of Loading a Saved mode, select model to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_SOURCE == 'Saved_model':\n",
    "    # LAST MODEL SAVED:\n",
    "    last_saved_model = get_latest_saved_model()\n",
    "    last_saved_model = last_saved_model[:19]+'.checkpoint'\n",
    "    print('Last saved model: ')\n",
    "    print(last_saved_model)\n",
    "\n",
    "    # ALL MODELS SAVED:\n",
    "    MODELS_FOLDER = 'models_saved/'\n",
    "    print('All saved models: ')\n",
    "    !ls \"{MODELS_FOLDER}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print execution parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution Summary:\")\n",
    "print(\"Datetime: \", get_current_datetime())\n",
    "print(\"SUPERVISED Annotated Dataset: \", filename_sa)\n",
    "print(\"DISTANT Annotated Dataset: \", filename_da)\n",
    "print(\"Training data source: \", training_source)\n",
    "print(\"Validation data source: \", validation_source)\n",
    "print('train/valid. split: ',test_size)\n",
    "print('save_model: ', save_model)\n",
    "print('Max length:' , max_len)\n",
    "print('Batch Size: ', bs )\n",
    "print('batch_num: ', bs)\n",
    "print('learning_rate: ', lr)\n",
    "print('eps: ', eps)\n",
    "print('Epochs: ', epochs)\n",
    "print('FULL_FINETUNING', FULL_FINETUNING)\n",
    "print('MODEL_SOURCE', MODEL_SOURCE)\n",
    "print('selected_model', selected_model)\n",
    "print('Train_code: ', train_code)\n",
    "print('Train model: ', TRAIN_MODEL)\n",
    "print('get_training_data', get_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) INSTALL LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras                      2.4.3\n",
      "Keras-Preprocessing        1.1.2\n",
      "pytorch-pretrained-bert    0.6.2\n",
      "pytorch-transformers       1.2.0\n",
      "sagemaker-pytorch-training 1.3.3\n",
      "torch                      1.4.0\n",
      "torchvision                0.5.0\n",
      "transformers               4.2.2\n"
     ]
    }
   ],
   "source": [
    "# Check library version\n",
    "!pip list | grep -E 'transformers|torch|Keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip -q install -r requirements_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If all required packages are installed, set 'pip_install'= 'no', otherwise = 'yes to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip_install = 'yes' \n",
    "pip_install = 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing seqeval\n",
      "installing matplotlib\n",
      "installing seaborn\n",
      "installing transformers\n",
      "installing tensorflow\n",
      "installing keras\n",
      "\n",
      "Packages installed: \n",
      "Keras                      2.4.3\n",
      "Keras-Preprocessing        1.1.2\n",
      "pytorch-pretrained-bert    0.6.2\n",
      "pytorch-transformers       1.2.0\n",
      "sagemaker-pytorch-training 1.3.3\n",
      "torch                      1.4.0\n",
      "torchvision                0.5.0\n",
      "transformers               4.2.2\n"
     ]
    }
   ],
   "source": [
    "if pip_install == 'yes': \n",
    "    print('installing seqeval')\n",
    "    !pip install seqeval --quiet\n",
    "    print('installing matplotlib')\n",
    "    !pip install matplotlib --quiet\n",
    "    print('installing seaborn')\n",
    "    !pip install seaborn --quiet\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# % matplotlib inline\n",
    "\n",
    "if pip_install == 'yes': \n",
    "    print('installing transformers')\n",
    "#     !pip install transformers  #transformers v3.x\n",
    "    !pip install --upgrade transformers==4.2.2 --quiet\n",
    "    !pip install transformers[sentencepiece] --quiet #transformers v4.x\n",
    "\n",
    "    # INSTALLS FOR AWS SAGEMAKER STUDIO PY\n",
    "    print('installing tensorflow')\n",
    "    !pip install tensorflow --quiet\n",
    "    print('installing keras')\n",
    "    !pip install keras --quiet\n",
    "    \n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "        # from transformers import BertTokenizer, BertConfig\n",
    "        # from transformers import BertForTokenClassification, AdamW\n",
    "\n",
    "# Check library version\n",
    "print('')\n",
    "print('Packages installed: ')\n",
    "!pip list | grep -E 'transformers|torch|Keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing pytorch-pretrained-bert\n",
      "installing pytorch-transformers\n",
      "installing ipywidgets\n",
      "installing ipython notebook\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if pip_install == 'yes': \n",
    "    print('installing pytorch-pretrained-bert')\n",
    "    !pip install pytorch-pretrained-bert --quiet\n",
    "    print('installing pytorch-transformers')\n",
    "    !pip install pytorch-transformers --quiet\n",
    "    \n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "# from pytorch_pretrained_bert import BertForTokenClassification, BertAdam, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam\n",
    "# from transformers import BertTokenizer, BertConfig\n",
    "# from pytorch_transformers import BertModel, BertTokenizer, BertForTokenClassification, BertConfig\n",
    "# from transformers import BertModel, BertTokenizer, BertForTokenClassification, BertConfig\n",
    "import logging\n",
    "\n",
    "if pip_install == 'yes': \n",
    "    print('installing ipywidgets')\n",
    "    !pip install ipywidgets --quiet\n",
    "    print('installing ipython notebook')\n",
    "    !pip install ipython notebook --quiet \n",
    "    !jupyter nbextension enable --py widgetsnbextension\n",
    "    \n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TWICE IF ERROR (IF STILL ERROR RESTART THE ENVIRONMENT)\n",
    "from transformers import BertModel, BertTokenizer, BertForTokenClassification, BertConfig\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) RUN FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_with_breakpoints(yesno):\n",
    "    if yesno == 'yes':\n",
    "        execution_mode = 'with_breakpoints'\n",
    "    else:\n",
    "        execution_mode = 'no_breakpoints'\n",
    "    return execution_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_breakpoint(execution_mode):\n",
    "    if execution_mode == 'with_breakpoints':\n",
    "        stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_BIO_data_into_sentences(data):\n",
    "    #concat sentence\n",
    "    getter = SentenceGetter(data)\n",
    "    \n",
    "    sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "    sentences_sbw = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "    labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
    "    return sentences, sentences_sbw, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_values_tag2idx_idx2tag_tag2name(data):\n",
    "\n",
    "    tags_vals = list(set(data[\"Tag\"].values))\n",
    "    \n",
    "    tags_vals = sorted(tags_vals)\n",
    "\n",
    "    # Add some additional tags:\n",
    "    # X  tag for word piece support\n",
    "    # [CLS] and [SEP] as BERT need\n",
    "    tags_vals.append('X')\n",
    "    tags_vals.append('[CLS]')\n",
    "    tags_vals.append('[SEP]')\n",
    "    tags_vals.append(\"PAD\")\n",
    "\n",
    "    tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "    idx2tag = {i: t for i, t in enumerate(tags_vals) }\n",
    "\n",
    "    print('tags_vals: ', tags_vals)\n",
    "    print('tag2idx: ', tag2idx)\n",
    "    print('idx2tag: ', idx2tag)\n",
    "\n",
    "    tag_values = tags_vals\n",
    "    \n",
    "    # Mapping tag to name\n",
    "    tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
    "    print('tag2name: ', tag2name)\n",
    "\n",
    "    return tags_vals, tag_values, tag2idx, idx2tag, tag2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unit testing\n",
    "# tags_vals, tag_values, tag2idx, idx2tag, tag2name = tag_values_tag2idx_idx2tag_tag2name(data)\n",
    "# tags_vals, tag_values, tag2idx, idx2tag, tag2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT TOKENIZATION and EXTENSION OF LABELS FOR SPLITTED TOKENS\n",
    "def tokenize_texts_extend_labels(sentences, labels):\n",
    "    tokenized_texts = []\n",
    "    tokenized_labels = []\n",
    "    for sent, labs in zip(sentences, labels):\n",
    "        tokenized_sentence = []\n",
    "        labels = []\n",
    "\n",
    "        sent_tokens = sent.split()\n",
    "        for word, label in zip(sent_tokens, labs):\n",
    "\n",
    "            # Tokenize the word and count # of subwords the word is broken into\n",
    "            tokenized_word = tokenizer.tokenize(word)\n",
    "            n_subwords = len(tokenized_word)\n",
    "\n",
    "            # Add the tokenized word to the final tokenized word list\n",
    "            tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "            # Add the same label to the new list of labels `n_subwords` times\n",
    "            labels.extend([label] * n_subwords)\n",
    "\n",
    "        tokenized_texts.append(tokenized_sentence)\n",
    "        tokenized_labels.append(labels)\n",
    "    \n",
    "    return tokenized_texts, tokenized_labels\n",
    "\n",
    "# tokenized_texts, tokenized_labels = tokenize_texts_extend_labels(sentences, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts_and_labels(tokenizer, max_len, sentences, labels, tag2idx):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "    #TOKENIZE TEXTS and LABELS:\n",
    "    tokenized_texts, tokenized_labels = tokenize_texts_extend_labels(sentences, labels)\n",
    "    \n",
    "    # SGD (added to comply with previous versions of code)\n",
    "    word_piece_labels = tokenized_labels\n",
    "\n",
    "    # INPUT IDs:\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen=max_len, dtype=\"long\", value=0.0,\n",
    "                              truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # TAGS:\n",
    "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in tokenized_labels],\n",
    "                         maxlen=max_len, value=tag2idx[\"PAD\"], padding=\"post\",\n",
    "                         dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "    # ATTENTION MASKS:\n",
    "    attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
    "        \n",
    "        \n",
    "    return tokenized_texts, tokenized_labels, word_piece_labels, input_ids, tags, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT TOKENS OF A GIVEN SENTENCE:\n",
    "\n",
    "def print_tokens_of_a_given_sentence(n):\n",
    "\n",
    "    # n = 232\n",
    "\n",
    "    print(\"TOKENIZED TEXT:\")\n",
    "    print(len(tokenized_texts[n]))\n",
    "    print(tokenized_texts[n])\n",
    "    print(\"-\"*160)\n",
    "    #\n",
    "    print(\"TOKEN LABELS:\")\n",
    "    print(len(labels[n]))\n",
    "    print(labels[n])\n",
    "    print(\"-\"*160)\n",
    "    #\n",
    "    print('- word_piece_labels:')\n",
    "    print(len(word_piece_labels[n]))\n",
    "    print(word_piece_labels[n])\n",
    "    print(\"-\"*160)\n",
    "    #\n",
    "    # print(\"tokens_ids:\")\n",
    "    # print(len(tokens_ids[n]))\n",
    "    # print(tokens_ids[n])\n",
    "    # print(\"-\"*160) \n",
    "    #\n",
    "    print(\"input_ids:\")\n",
    "    print(len(input_ids[n]))\n",
    "    print(input_ids[n])\n",
    "    print(\"-\"*160)\n",
    "    #\n",
    "    # print(\"t_list:\")\n",
    "    # print(t_list[n])\n",
    "    # print(\"-\"*160)\n",
    "    #\n",
    "    print('tags')\n",
    "    print(len(tags[n]))\n",
    "    print(tags[n])\n",
    "    print(\"-\"*160)\n",
    "    #\n",
    "    print('attention_masks')\n",
    "    print(len(attention_masks[n]))\n",
    "    print(attention_masks[n])\n",
    "    print(\"-\"*160)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Validation Metrics:\n",
    "\n",
    "# Import f1_score from sequeval.metrics\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "\n",
    "# define function to flatten accuracy\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_validation_loss(loss_values, validation_loss_values):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Use plot styling from seaborn.\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    # Increase the plot size and font size.\n",
    "    sns.set(font_scale=1.5)\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "    # Plot the learning curve.\n",
    "    plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
    "    plt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "    # Label the plot.\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CONFUSION MATRIX:\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix'):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=None)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_matrix(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "#     class_names = [\"O\", \"B-PROD\", \"I-PROD\", \"X\",\"[CLS]\",\"[SEP]\"]\n",
    "    class_names = [\"B-PROD\", \"I-PROD\", \"O\"]\n",
    "    plot_confusion_matrix(confusion_matrix\n",
    "                          , classes=class_names\n",
    "                          , title='Confusion matrix')\n",
    "    \n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "    class_names = [\"B-PROD\", \"I-PROD\", \"O\"]\n",
    "    return confusion_matrix, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_true_pred_labels(y_true, y_pred):\n",
    "    \n",
    "    y_true_flat = []\n",
    "\n",
    "    for s in y_true:\n",
    "        for t in s:\n",
    "            y_true_flat.append(t)\n",
    "            \n",
    "    y_pred_flat = []\n",
    "\n",
    "    for s in y_pred:\n",
    "        for t in s:\n",
    "            y_pred_flat.append(t)\n",
    "            \n",
    "    return y_true_flat, y_pred_flat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_datetime():\n",
    "    # using time module \n",
    "    import time \n",
    "    from datetime import datetime\n",
    "\n",
    "    # ts stores the time in seconds \n",
    "    ts = time.time() \n",
    "    # print(ts) \n",
    "\n",
    "    #convert timestamp to date/time\n",
    "    dt_object = datetime.fromtimestamp(ts)\n",
    "    # print(\"dt_object =\", dt_object)\n",
    "    # print(\"type(dt_object) =\", type(dt_object))\n",
    "\n",
    "    #get datetime\n",
    "    datetime = str(dt_object)\n",
    "    datetime = datetime[:19]\n",
    "\n",
    "    return datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE TRAINED MODEL\n",
    "\n",
    "def save_trained_model(BASE_FOLDER):\n",
    "    datetime = get_current_datetime()\n",
    "    datetime = datetime.replace(':', '-')\n",
    "\n",
    "    # print(ts)\n",
    "    # print(datetime)\n",
    "\n",
    "    #set bert_out_address \n",
    "    bert_out_address = BASE_FOLDER+str(datetime)\n",
    "\n",
    "    # Make dir if not exits\n",
    "    if not os.path.exists(bert_out_address):\n",
    "            os.makedirs(bert_out_address)\n",
    "\n",
    "    # Save a trained model, configuration and tokenizer\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\n",
    "    # If we save using the predefined names, we can load using `from_pretrained`\n",
    "    output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
    "    output_config_file = os.path.join(bert_out_address, \"config.json\")\n",
    "\n",
    "    # Save model into file\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    model_to_save.config.to_json_file(output_config_file)\n",
    "    tokenizer.save_vocabulary(bert_out_address)\n",
    "\n",
    "    return print('model ', datetime, ' saved to folder models_saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_trained_model_checkpoint(BASE_FOLDER, model, epoch, loss):\n",
    "#     datetime = get_current_datetime()\n",
    "#     datetime = datetime.replace(':', '-')\n",
    "\n",
    "#     # print(ts)\n",
    "#     # print(datetime)\n",
    "\n",
    "#     #set bert_out_address \n",
    "#     PATH = BASE_FOLDER+str(datetime)\n",
    "\n",
    "#     # Make dir if not exits\n",
    "#     if not os.path.exists(bert_out_address):\n",
    "#             os.makedirs(bert_out_address)\n",
    "    \n",
    "    \n",
    "#     torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'loss': loss,\n",
    "#             ...\n",
    "#             }, PATH)\n",
    "\n",
    "#     # Save a trained model, configuration and tokenizer\n",
    "#     model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\n",
    "#     # If we save using the predefined names, we can load using `from_pretrained`\n",
    "#     output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
    "#     output_config_file = os.path.join(bert_out_address, \"config.json\")\n",
    "\n",
    "#     # Save model into file\n",
    "#     torch.save(model_to_save.state_dict(), output_model_file)\n",
    "#     model_to_save.config.to_json_file(output_config_file)\n",
    "#     tokenizer.save_vocabulary(bert_out_address)\n",
    "\n",
    "#     return print('model ', datetime, ' saved to folder models_saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_saved_model():\n",
    "\n",
    "    import os.path\n",
    "    import glob\n",
    "    import datetime\n",
    "\n",
    "    path = 'models_saved/'\n",
    "    list_of_files = glob.glob('models_saved/2021*')\n",
    "    list_of_files\n",
    "\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    _, filename = os.path.split(latest_file)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(BASE_FOLDER, model_name):\n",
    "    # set model to be loadaed\n",
    "    bert_out_address = BASE_FOLDER + model_name\n",
    "\n",
    "    model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=7)\n",
    "\n",
    "    # Set model to GPU\n",
    "    model.cuda()\n",
    "\n",
    "    if n_gpu >1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sap_bert(test_sentence, inference_model):\n",
    "    \n",
    "    model = inference_model\n",
    "    \n",
    "    test_sentence = test_sentence.lower()\n",
    "\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "    tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "    #print('tokenized_sentence: ', tokenized_sentence)\n",
    "    \n",
    "    input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "    #print('label_indices: ', label_indices)\n",
    "\n",
    "    # join bpe split tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "    #print('tokens: ', tokens)\n",
    "    \n",
    "    new_tokens, new_labels = [], []\n",
    "    for token, label_idx in zip(tokens, label_indices[0]):\n",
    "        if token.startswith(\"##\"):\n",
    "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "        else:\n",
    "            new_labels.append(tag_values[label_idx])\n",
    "            new_tokens.append(token)\n",
    "\n",
    "#     for token, label in zip(new_tokens, new_labels):\n",
    "#         print(\"{}\\t{}\".format(label, token))\n",
    "        \n",
    "    prediction = {\"Token\": new_tokens, \"Label\": new_labels}\n",
    "    df = pd.DataFrame(prediction)\n",
    "    \n",
    "    df2 = df[df['Token'] != '[CLS]']   \n",
    "    prediction_df = df2[df2['Token'] != '[SEP]'] \n",
    "        \n",
    "    return prediction_df\n",
    "\n",
    "def inference_sap_bert_to_list(test_sentence, inference_model):\n",
    "    \n",
    "    prediction_df = inference_sap_bert(test_sentence, inference_model)\n",
    "    prediction_list = prediction_df.values.tolist()\n",
    "\n",
    "    return prediction_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNIT TESTING (SGD)\n",
    "# # OTHER SAMPLE SENTENCES:\n",
    "# test_sentence = 'should be presented sap cloud platform sap_hana backup data ssp backup data etc databackup sstadm sap hana backup prod stop hybris process on all hybris app servers incl'\n",
    "# test_sentence = 'ng div sap_hana div li li href shop by cloud platform sb cloud img class solution tile icon emptyprimaryimage src medias sap hana_cloud_platform icon'\n",
    "\n",
    "# test_sentence = 'as sap gold partner delaware consulting and sap work together to implement sap s4hana cloud for rehau which is the first s/4hana live customer in china' \n",
    "\n",
    "# # test_sentence = 'the company says that the combination of sap cloud platform with sap business technology platform is all about connecting business processes and experiences so asug members can make confident decisions with integrity'\n",
    "\n",
    "# inference_sap_bert(test_sentence, model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LANGUAGE DETECTION WITH SPACY:\n",
    "# !pip install spacy-langdetect\n",
    "# !python -m spacy download en\n",
    "\n",
    "# import spacy\n",
    "# from spacy_langdetect import LanguageDetector\n",
    "# nlp = spacy.load('en')\n",
    "# nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def language_detection(text):\n",
    "#     doc = nlp(text)\n",
    "#     # document level language detection. Think of it like average language of the document!\n",
    "#     #print(doc._.language)\n",
    "#     language_score = doc._.language\n",
    "#     # sentence level language detection\n",
    "# #     for sent in doc.sents:\n",
    "# #         print(sent, sent._.language)\n",
    "#     return language_score\n",
    "\n",
    "# text = 'This is an english text.'\n",
    "# language_score = language_detection(text)\n",
    "# language_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def english_yes_no(language_score):\n",
    "#     language = language_score['language']\n",
    "#     score = language_score['score']\n",
    "    \n",
    "#     if language == 'en' and score > 0.80:\n",
    "#         veredict = 'yes'\n",
    "#     else:\n",
    "#         veredict = 'no'\n",
    "#     return veredict\n",
    "\n",
    "# print(english_yes_no(language_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTING:\n",
    "\n",
    "# filename='scw_01-23_sa_v6.csv'\n",
    "# max_len=256\n",
    "# bs=16\n",
    "# test_size=0.2\n",
    "# base_folder='training-datasets/'\n",
    "# BASE_FOLDER='training-datasets/'\n",
    "\n",
    "# data = pd.read_csv(BASE_FOLDER+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')    \n",
    "    \n",
    "# print('data loaded from: ', filename)\n",
    "# print(data.describe())\n",
    "# print(data.Tag.value_counts())\n",
    "# print('-'*20)\n",
    "# sentences, sentences_sbw, labels = turn_BIO_data_into_sentences(data)\n",
    "# tags_vals, tag_values, tag2idx, idx2tag, tag2name = tag_values_tag2idx_idx2tag_tag2name(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Train/Validation Dataset (Tokenized, Tensors and DataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unit testing:\n",
    "# BASE_FOLDER = 'training-datasets/'\n",
    "# filename = 'scw_01-23_sa_v6.csv'\n",
    "\n",
    "# data = pd.read_csv(BASE_FOLDER+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')    \n",
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_FOLDER = 'training-datasets/'\n",
    "# filename = '2021-03-21_14-02-50_01-272_INFER_PL1.csv'\n",
    "\n",
    "# data = pd.read_csv(BASE_FOLDER+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')    \n",
    "# data\n",
    "# data.describe()\n",
    "# print('data loaded from: ', filename)\n",
    "# print(data.describe())\n",
    "# print(data.Tag.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_validation_dataset(filename, max_len, bs, test_size, base_folder):\n",
    "    if base_folder == '':\n",
    "        BASE_FOLDER = 'training-datasets/'\n",
    "    else:\n",
    "        BASE_FOLDER = base_folder\n",
    "        \n",
    "    data = pd.read_csv(BASE_FOLDER+filename,sep=\",\",encoding=\"latin1\").fillna(method='ffill')    \n",
    "    \n",
    "    print('data loaded from: ', filename)\n",
    "    print(data.describe())\n",
    "    print(data.Tag.value_counts())\n",
    "    \n",
    "    sentences, sentences_sbw, labels = turn_BIO_data_into_sentences(data)\n",
    "    \n",
    "    tags_vals, tag_values, tag2idx, idx2tag, tag2name = tag_values_tag2idx_idx2tag_tag2name(data)\n",
    "    \n",
    "    # Set GPUs \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    torch.cuda.get_device_name(0)\n",
    "    \n",
    "    # TOKENIZE TEXTS AND LABELS:\n",
    "    max_len = 256\n",
    "    MAX_LEN = max_len\n",
    "    model_max_length = max_len\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "    tokenized_texts, tokenized_labels, word_piece_labels, input_ids, tags, attention_masks = tokenize_texts_and_labels(tokenizer, max_len, sentences, labels, tag2idx)\n",
    "\n",
    "    # SPLIT TRAINING/ VALIDATION DATASET:\n",
    "    tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                                random_state=2018, test_size=test_size)\n",
    "    tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                                 random_state=2018, test_size=test_size)\n",
    "\n",
    "    # CONVERT TO TORCH TENSORS (since we are operating in Pytorch)\n",
    "    tr_inputs = torch.tensor(tr_inputs)\n",
    "    val_inputs = torch.tensor(val_inputs)\n",
    "    tr_tags = torch.tensor(tr_tags)\n",
    "    val_tags = torch.tensor(val_tags)\n",
    "    tr_masks = torch.tensor(tr_masks)\n",
    "    val_masks = torch.tensor(val_masks)\n",
    "    \n",
    "    # SET BATCH-SIZE (BS): val_inputs, tag2name\n",
    "    bs = 16\n",
    "    batch_num = bs\n",
    "    \n",
    "    # DEFINE DATALOADERS: \n",
    "    #We shuffle the data at training time with the RandomSampler \n",
    "    # and at test time we just pass them sequentially with the SequentialSampler.\n",
    "    train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "    valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "    valid_sampler = SequentialSampler(valid_data)\n",
    "    valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n",
    "    \n",
    "    return train_data, train_sampler, train_dataloader, valid_data, valid_sampler, valid_dataloader, tag2idx, tag_values, input_ids, tags, attention_masks, val_inputs, tag2name, idx2tag, val_masks, val_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJECUCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_mode = execution_with_breakpoints('no')  # 'yes'or 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries for retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow --quiet\n",
    "# !pip install keras --quiet\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "# import math\n",
    "# import numpy as np\n",
    "# from seqeval.metrics import f1_score\n",
    "# from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import os\n",
    "# from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPUs \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Execution parameters (moded to top of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXECUTION PARAMETERS:\n",
    "\n",
    "# #-----------------------------\n",
    "# # base folder:\n",
    "# #-----------------------------\n",
    "# base_folder = 'training-datasets/'\n",
    "\n",
    "\n",
    "# #-----------------------------\n",
    "# # dataset source files:\n",
    "# #-----------------------------\n",
    "# filename_sa = 'scw_01-23_sa_v6.csv'\n",
    "\n",
    "\n",
    "# # filename_da = '2021-03-21_14-02-50_01-272_INFER_PL1.csv'\n",
    "# # filename_da = 'scw_01_23_da.csv'\n",
    "# # filename_da = 'scw_24_49_da.csv'\n",
    "# # filename_da = 'scw_50_99_da.csv'\n",
    "# # filename_da = 'scw_100_149_da.csv'\n",
    "# # filename_da = 'scw_1-149_220-272_da.csv'\n",
    "# # filename_da = 'scw_nhve_1-149_220-272_da.csv'\n",
    "# # filename_da = 'scw_220_272_da.csv'\n",
    "# filename_da = '2021-03-22_01-22-44_nhve_scw_220_272_INFER.csv'\n",
    "\n",
    "# #-----------------------------\n",
    "# # select datasources for current execution:\n",
    "# #-----------------------------\n",
    "# training_source = 'sa'\n",
    "# validation_source = 'da'\n",
    "\n",
    "# #-----------------------------\n",
    "# # SAVE MODEL \n",
    "# #-----------------------------\n",
    "# save_model = 'no'\n",
    "# # save_model = 'yes'\n",
    "\n",
    "# #-----------------------------\n",
    "# # TRAINING PARAMETERS\n",
    "# #-----------------------------\n",
    "# max_len = 256   # Max length:\n",
    "# bs = 16         # Batch size: 2, 4, 8, 16\n",
    "# batch_num = bs  # Batch Size:\n",
    "# test_size = 0.3 # Validation/Test Split:\n",
    "# lr = 5e-5       # Learning rate: 1e-5, 2e-5, 3e-5, 5e-5 \n",
    "# eps = 1e-8      # EPS\n",
    "# epochs = 3     # Epochs: 2,3,4,5\n",
    "\n",
    "# #-----------------------------\n",
    "# # Set Finetunning depth:\n",
    "# #-----------------------------\n",
    "# FULL_FINETUNING = True   # True: fine tuning all the layers \n",
    "# # FULL_FINETUNNING = False # False: only fine tuning the classifier layers\n",
    "\n",
    "# #-----------------------------\n",
    "# # MODEL TRAIN CODE VERSION: \n",
    "# #-----------------------------\n",
    "# # train_code = 'OLD_CODE'\n",
    "# train_code = 'NEW_CODE'\n",
    "\n",
    "# #-----------------------------\n",
    "# # SET MODEL SOURCE\n",
    "# #-----------------------------\n",
    "# MODEL_SOURCE = 'Transformers'\n",
    "# selected_model = ''\n",
    "\n",
    "# # MODEL_SOURCE = 'Saved_model'\n",
    "# # selected_model = '2021-03-21_14-02-50.checkpoint'\n",
    "\n",
    "# #-----------------------------\n",
    "# # TRAIN MODEL:\n",
    "# #-----------------------------\n",
    "# TRAIN_MODEL = 'yes'\n",
    "# # TRAIN_MODEL = 'no'\n",
    "\n",
    "# #-----------------------------\n",
    "# # GET TRAINING DATA\n",
    "# #-----------------------------\n",
    "# get_training_data = 'yes'\n",
    "# # get_training_data = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case of Loading a Saved mode, select model to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if MODEL_SOURCE == 'Saved_model':\n",
    "#     # LAST MODEL SAVED:\n",
    "#     last_saved_model = get_latest_saved_model()\n",
    "#     last_saved_model = last_saved_model[:19]+'.checkpoint'\n",
    "#     print('Last saved model: ')\n",
    "#     print(last_saved_model)\n",
    "\n",
    "#     # ALL MODELS SAVED:\n",
    "#     MODELS_FOLDER = 'models_saved/'\n",
    "#     print('All saved models: ')\n",
    "#     !ls \"{MODELS_FOLDER}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print execution parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Execution Summary:\")\n",
    "# print(\"Datetime: \", get_current_datetime())\n",
    "# print(\"SUPERVISED Annotated Dataset: \", filename_sa)\n",
    "# print(\"DISTANT Annotated Dataset: \", filename_da)\n",
    "# print(\"Training data source: \", training_source)\n",
    "# print(\"Validation data source: \", validation_source)\n",
    "# print('train/valid. split: ',test_size)\n",
    "# print('save_model: ', save_model)\n",
    "# print('Max length:' , max_len)\n",
    "# print('Batch Size: ', bs )\n",
    "# print('batch_num: ', bs)\n",
    "# print('learning_rate: ', lr)\n",
    "# print('eps: ', eps)\n",
    "# print('Epochs: ', epochs)\n",
    "# print('FULL_FINETUNING', FULL_FINETUNING)\n",
    "# print('MODEL_SOURCE', MODEL_SOURCE)\n",
    "# print('selected_model', selected_model)\n",
    "# print('Train_code: ', train_code)\n",
    "# print('Train model: ', TRAIN_MODEL)\n",
    "# print('get_training_data', get_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LOAD TRAINING/VALIDATION DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a) from SUPERVISED Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Train/Validation data from SUPERVISED Annptated Dataset\n",
    "if get_training_data == 'yes':\n",
    "    \n",
    "#     test_size = 0.3\n",
    "    \n",
    "    train_data_sa, train_sampler_sa, train_dataloader_sa, valid_data_sa, valid_sampler_sa, valid_dataloader_sa, tag2idx, tag_values, input_ids, tags, attention_masks, val_inputs, tag2name, idx2tag, val_masks, val_tags = get_train_validation_dataset(filename_sa, max_len, bs, test_size, base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_sa, max_len, bs, test_size, base_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b) from DISTANT Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Train/Validation data from DISTANT Annotated Dataset\n",
    "if get_training_data == 'yes':\n",
    "    \n",
    "    train_data_da, train_sampler_da, train_dataloader_da, valid_data_da, valid_sampler_da, valid_dataloader_da, tag2idx, tag_values, input_ids, tags, attention_masks, val_inputs, tag2name, idx2tag, val_masks, val_tags = get_train_validation_dataset(filename_da, max_len, bs, test_size, base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) COMBINE FINAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY THE CORRESPONDING DATASETS TO THE FINAL CONTAINERS/DATALOADERS:\n",
    "if get_training_data == 'yes':\n",
    "    \n",
    "    if training_source == 'da':\n",
    "        train_data = train_data_da\n",
    "        train_sampler = train_sampler_da\n",
    "        train_dataloader = train_dataloader_da\n",
    "    elif training_source == 'sa':\n",
    "        train_data = train_data_sa\n",
    "        train_sampler = train_sampler_sa\n",
    "        train_dataloader = train_dataloader_sa\n",
    "    else:\n",
    "        print('please enter a valid training_source, either da or sa')\n",
    "\n",
    "    if training_source == 'da':\n",
    "        valid_data = valid_data_da\n",
    "        valid_sampler = valid_sampler_da\n",
    "        valid_dataloader = valid_dataloader_da\n",
    "    elif training_source == 'sa':\n",
    "        valid_data = valid_data_sa\n",
    "        valid_sampler = valid_sampler_sa\n",
    "        valid_dataloader = valid_dataloader_sa\n",
    "    else:\n",
    "        print('please enter a valid validation_source, either da or sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) IMPORT MODEL (from transformers library or a Saved Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_SOURCE == 'Transformers':\n",
    "    from transformers import BertForTokenClassification, AdamW\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(tag2idx),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False)\n",
    "    \n",
    "elif MODEL_SOURCE == 'Saved_model':\n",
    "    from transformers import BertForTokenClassification, AdamW\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    #num_labels=len(tag2idx),\n",
    "    num_labels= 7,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False)\n",
    "\n",
    "    PATH = MODELS_FOLDER+selected_model\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    # LOAD tag2idx, idx2tag, tag2name from file: \n",
    "    import pickle\n",
    "\n",
    "    # tag2idx\n",
    "    file = open(MODELS_FOLDER+selected_model[:19]+'_'+'tag2idx', 'rb')\n",
    "    tag2idx = pickle.load(file)\n",
    "    print(tag2idx)\n",
    "\n",
    "    # idx2tag\n",
    "    file = open(MODELS_FOLDER+selected_model[:19]+'_'+'idx2tag', 'rb')\n",
    "    idx2tag = pickle.load(file)\n",
    "    print(idx2tag)\n",
    "\n",
    "    # tag2name\n",
    "    file = open(MODELS_FOLDER+selected_model[:19]+'_'+'tag2name', 'rb')\n",
    "    tag2name = pickle.load(file)\n",
    "    print(tag2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funtion for loading model checkpoint, optimizer and loss:\n",
    "# def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "#     \"\"\"\n",
    "#     checkpoint_path: path to save checkpoint\n",
    "#     model: model that we want to load checkpoint parameters into       \n",
    "#     optimizer: optimizer we defined in previous training\n",
    "#     \"\"\"\n",
    "#     # load check point\n",
    "#     checkpoint = torch.load(checkpoint_fpath)\n",
    "#     # initialize state_dict from checkpoint to model\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     # initialize optimizer from checkpoint to optimizer\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#     # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "#     valid_loss_min = checkpoint['valid_loss_min']\n",
    "#     # return model, optimizer, epoch value, min validation loss \n",
    "#     return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the model parameters to the GPU.\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Set-up Transformer Optimization:\n",
    "https://huggingface.co/transformers/_modules/transformers/optimization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Set Full_finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True: fine tuning all the layers \n",
    "# False: only fine tuning the classifier layers\n",
    "# FULL_FINETUNING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Set parameters and Instantiate optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters:\n",
    "# lr=3e-5\n",
    "# eps=1e-8\n",
    "\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "# Instantiate Optimizer:\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=lr,\n",
    "    eps=eps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Add Linear LR Schedule with warm-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler to linearly reduce the learning rate throughout the epochs\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# get_linear_schedule_with_warmup: Creates a schedule with a constant LR \n",
    "#(learning rate) preceded by a warmup period during which the LR increases\n",
    "#linearly between 0 and the initial LR set in the optimizer.\n",
    "\n",
    "# epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Get Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) TRAIN/ Fine-Tune BERT model for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE:\n",
    "\n",
    "# if train_code == 'NEW_CODE':\n",
    "if TRAIN_MODEL == 'yes':\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    ## Store the average loss after each epoch so we can plot them.\n",
    "    loss_values, validation_loss_values = [], []\n",
    "\n",
    "    # epochs = 5\n",
    "\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "        # Perform one full pass over the training set.\n",
    "        \n",
    "        # see here BERT Transformers Moddel documentation: https://huggingface.co/transformers/main_classes/output.html \n",
    "\n",
    "        # Put the model into training mode.\n",
    "        model.train()\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            # Always clear any previously calculated gradients before performing a \n",
    "            #backward pass.\n",
    "            model.zero_grad()\n",
    "            # forward pass\n",
    "\n",
    "            labels = torch.tensor([1,0]).unsqueeze(0)\n",
    "\n",
    "            # NEW CODE:\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # logits: Classification scores (before SoftMax). (torch.FloatTensor of shape (batch_size, sequence_length, config.num_labels))\n",
    "            # loss: Classification loss. (torch.FloatTensor of shape (1,), optional, returned when labels is provided)\n",
    "            \n",
    "            # or\n",
    "    #         from torch.nn import functional as F\n",
    "    #         labels = torch.tensor([1,0])\n",
    "    #         outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    #         # Move logits and labels to CPU\n",
    "    # #         logits = outputs[1].detach().cpu().numpy()\n",
    "    #         label_ids = b_labels.to('cpu').numpy()\n",
    "    #         loss = F.cross_entropy(outputs.logits, labels=labels_ids)\n",
    "            # END NEW CODE:\n",
    "\n",
    "            # BEGIN OLD CODE:\n",
    "    #         # This will return the loss (rather than the model output)\n",
    "    #         # because we have provided the `labels`.\n",
    "    #         outputs = model(b_input_ids, token_type_ids=None,\n",
    "    #                         attention_mask=b_input_mask, labels=b_labels)\n",
    "    #         # get the loss\n",
    "    #         loss = outputs[0]\n",
    "            # END OLD CODE\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            total_loss += loss.item()\n",
    "            # Clip the norm of the gradient\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over the training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "        # Store the loss value for plotting the learning curve.\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        # Put the model into evaluation mode\n",
    "        model.eval()\n",
    "        # Reset the validation loss for this epoch.\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        predictions , true_labels = [], []\n",
    "        for batch in valid_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Telling the model not to compute or store gradients,\n",
    "            # saving memory and speeding up validation\n",
    "            with torch.no_grad():\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # This will return the logits rather than the loss because we have not provided labels.\n",
    "                outputs = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "            # Move logits and labels to CPU\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences.\n",
    "            eval_loss += outputs[0].mean().item()\n",
    "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "            true_labels.extend(label_ids)\n",
    "\n",
    "        eval_loss = eval_loss / len(valid_dataloader)\n",
    "        validation_loss_values.append(eval_loss)\n",
    "        print(\"Validation loss: {}\".format(eval_loss))\n",
    "        pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                     for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "        valid_tags = [tag_values[l_i] for l in true_labels\n",
    "                                      for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "        print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "    #     print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Execution Summary:\")\n",
    "print(\"Datetime: \", get_current_datetime())\n",
    "print(\"SUPERVISED Annotated Dataset: \", filename_sa)\n",
    "print(\"DISTANT Annotated Dataset: \", filename_da)\n",
    "print(\"Training data source: \", training_source)\n",
    "print(\"Validation data source: \", validation_source)\n",
    "print('train/valid. split: ',test_size)\n",
    "print('save_model: ', save_model)\n",
    "print('Max length:' , max_len)\n",
    "print('Batch Size: ', bs )\n",
    "print('batch_num: ', bs)\n",
    "print('learning_rate: ', lr)\n",
    "print('eps: ', eps)\n",
    "print('Epochs: ', epochs)\n",
    "print('FULL_FINETUNING', FULL_FINETUNING)\n",
    "print('MODEL_SOURCE', MODEL_SOURCE)\n",
    "print('selected_model', selected_model)\n",
    "print('Train_code: ', train_code)\n",
    "print('get_training_data', get_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Execution Summary:\")\n",
    "# print(\"Datetime: \")\n",
    "# print(\"SUPERVISED Annotated Dataset: \")\n",
    "# print(\"DISTANT Annotated Dataset: \")\n",
    "# print(\"Training data source: \")\n",
    "# print(\"Validation data source: \")\n",
    "# print('train/valid. split: ')\n",
    "# print('save_model: ')\n",
    "# print('Max length:' )\n",
    "# print('Batch Size: ')\n",
    "# print('batch_num: ')\n",
    "# print('learning_rate: ')\n",
    "# print('eps: ')\n",
    "# print('Epochs: ')\n",
    "# print('MODEL_SOURCE')\n",
    "# print('selected_model')\n",
    "# print('Train_code: ')\n",
    "# print('get_training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Execution Summary:\")\n",
    "# print(get_current_datetime())\n",
    "# print(filename_sa)\n",
    "# print(filename_da)\n",
    "# print(training_source)\n",
    "# print(validation_source)\n",
    "# print(test_size)\n",
    "# print(save_model)\n",
    "# print(max_len)\n",
    "# print(bs )\n",
    "# print(bs)\n",
    "# print(lr)\n",
    "# print(eps)\n",
    "# print(epochs)\n",
    "# print(FULL_FINETUNING)\n",
    "# print(MODEL_SOURCE)\n",
    "# print(selected_model)\n",
    "# print(train_code)\n",
    "# print(get_training_data)\n",
    "# print(train_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_validation_loss(loss_values, validation_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) EVALUATE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION: (FROM V.2)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "bert_out_address = \"models_evaluation/\"\n",
    "datetime = get_current_datetime()\n",
    "filename_prefix = str(datetime)+'_'\n",
    "\n",
    "print(\"***** Running evaluation *****\")\n",
    "# print(\"  Num examples ={}\".format(len(val_inputs)))\n",
    "print(\"  Batch size = {}\".format(batch_num))\n",
    "\n",
    "for step, batch in enumerate(valid_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "    \n",
    "#     if step > 2:\n",
    "#         break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "    \n",
    "    # Get NER predict result\n",
    "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "\n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    \n",
    "    \n",
    "    # Only predict the real word, mark=0, will not calculate\n",
    "    input_mask = input_mask.to('cpu').numpy()\n",
    "    \n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # Real one\n",
    "        temp_1 = []\n",
    "        # Predict one\n",
    "        temp_2 = []\n",
    "        \n",
    "        for j, m in enumerate(mask):\n",
    "            # Mark=0, meaning its a pad word, dont compare\n",
    "            if m:\n",
    "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
    "                    temp_1.append(tag2name[label_ids[i][j]])\n",
    "                    temp_2.append(tag2name[logits[i][j]])\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "            \n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "# Get acc , recall, F1 result report\n",
    "report = classification_report(y_true, y_pred,digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Evaluation Results\n",
    "print(\"***** Evaluation results *****\")\n",
    "print(\"\\ndatetime: \", datetime)\n",
    "print(\"  Num eval. predictions ={}\".format(len(y_pred)))        \n",
    "print(\"f1 score: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "print(\"\\n%s\"%(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLATTEN PREDICTIONS AND TRUE LABELS:\n",
    "y_true_flat, y_pred_flat = flatten_true_pred_labels(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['B-PROD', 'I-PROD', 'O']\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true_flat, y_pred_flat, target_names=target_names, digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET CONFUSSION MATRIX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_matrix(y_true_flat, y_pred_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix, class_names = get_confusion_matrix(y_true_flat, y_pred_flat)\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding 'y_pred' and 'y_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "print('y_true: ',y_true[n])\n",
    "print('y_pred: ', y_pred[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) SAVE Fine-Tuned Model, parameters, eval. results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_breakpoint(execution_mode) # insert to set breakpoint check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) SAVE  Trained Model checkpoint to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to save a checkpoint that allows us to use this information to continue our model training. Here is the information needed:\n",
    "- epoch: a measure of the number of times all of the training vectors are used once to update the weights.\n",
    "- valid_loss_min: the minimum validation loss, this is needed so that when we continue the training, we can start with this rather than np.Inf value.\n",
    "- state_dict: model architecture information. It includes the parameter matrices for each of the layers.\n",
    "- optimizer: You need to save optimizer parameters especially when you are using Adam as your optimizer. Adam is an adaptive learning rate method, which means, it computes individual learning rates for different parameters which we would need if we want to continue our training from where we left off [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE  Trained Model checkpoint to file\n",
    "BASE_FOLDER = 'models_saved/' \n",
    "datetime = get_current_datetime()\n",
    "datetime = datetime.replace(':', '-')\n",
    "datetime = datetime.replace(' ', '_')\n",
    "\n",
    "PATH = BASE_FOLDER+str(datetime)\n",
    "#PATH\n",
    "\n",
    "torch.save(model.state_dict(), PATH+'.checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) SAVE tag2idx, idx2tag, tag2name to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE tag2idx, idx2tag, tag2name to file\n",
    "\n",
    "import pickle\n",
    "\n",
    "MODELS_FOLDER = 'models_saved/'\n",
    "\n",
    "# tag2idx to file\n",
    "file = open(MODELS_FOLDER+datetime+'_'+'tag2idx', 'wb' )\n",
    "pickle.dump(tag2idx, file)\n",
    "file.close()\n",
    "\n",
    "# idx2tag to file\n",
    "file = open(MODELS_FOLDER+datetime+'_'+'idx2tag', 'wb' )\n",
    "pickle.dump(idx2tag, file)\n",
    "file.close()\n",
    "\n",
    "# tag2name to file\n",
    "file = open(MODELS_FOLDER+datetime+'_'+'tag2name', 'wb' )\n",
    "pickle.dump(tag2name, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN saved file (test)\n",
    "file = open(MODELS_FOLDER+datetime+'_'+'tag2idx', 'rb')\n",
    "tag2idx = pickle.load(file)\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3) SAVE Training Parameters to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE Model Parameters and Evaluation Results\n",
    "BASE_FOLDER = 'models_saved/'\n",
    "\n",
    "file = os.path.join(BASE_FOLDER, datetime+'_parameters')\n",
    "with open(file, \"w\") as writer:\n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write(\"\\nExecution Summary:   \")\n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write(\"\\nDatetime: \") \n",
    "    writer.write(get_current_datetime())\n",
    "    writer.write(\"\\nModel_name (generated): \") \n",
    "    writer.write(PATH)\n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write('\\nMODEL_SOURCE: ')\n",
    "    writer.write(MODEL_SOURCE)\n",
    "    writer.write('\\nselected_model: (if source= saved_model):  ')\n",
    "    writer.write(selected_model)\n",
    "    writer.write(\"\\n\\nSupervised Annotated Dataset: \") \n",
    "    writer.write(filename_sa)\n",
    "    writer.write(\"\\nDistant Annotated Dataset: \")\n",
    "    writer.write(filename_da)\n",
    "    writer.write(\"\\n\\nTraining data source: \")\n",
    "    writer.write(training_source)\n",
    "    writer.write(\"\\nValidation data source: \") \n",
    "    writer.write(validation_source)\n",
    "    writer.write('\\n--------------------------------------------------------------')\n",
    "    writer.write('\\nMax length: ')\n",
    "    writer.write(str(max_len))\n",
    "    writer.write('\\nBatch Size: ')\n",
    "    writer.write(str(bs))\n",
    "    writer.write('\\nLearning_rate: ')\n",
    "    writer.write(str(lr))\n",
    "    writer.write('\\nEPS: ') \n",
    "    writer.write(str(eps))\n",
    "    writer.write('\\nEpochs: ')\n",
    "    writer.write(str(epochs))\n",
    "    writer.write('\\n--------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4) SAVE Evaluation Results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(BASE_FOLDER, datetime+'_eval_metrics')\n",
    "with open(file, \"w\") as writer:\n",
    "    writer.write(\"\\nModel_name: \") \n",
    "    writer.write(PATH)\n",
    "    writer.write(\"\\n\\nEVALUATION METRICS: \")\n",
    "    writer.write(\"\\nf1 socre:  \")\n",
    "    writer.write(str(f1_score(y_true, y_pred)))\n",
    "    writer.write(\"\\nAccuracy score:  \")\n",
    "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
    "    writer.write(\"\\n\\n\")  \n",
    "    writer.write(report)\n",
    "    writer.write(\"\\nConfusion Matrix:  \")\n",
    "    #writer.write(str(class_names))\n",
    "    #writer.write(conf_matrix)\n",
    "    writer.write('\\nB-PROD: B-I-O ') \n",
    "    writer.write(str(conf_matrix[0]))\n",
    "    writer.write('\\nI-PROD: B-I-O ')\n",
    "    writer.write(str(conf_matrix[1]))     \n",
    "    writer.write('\\nO     : B-I-O ')\n",
    "    writer.write(str(conf_matrix[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('B-PROD: B-I-O ', str(conf_matrix[0]))\n",
    "print('I-PROD: B-I-O ', str(conf_matrix[1]))     \n",
    "print('O     : B-I-O ', str(conf_matrix[2]))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) INFERENCE model (unit testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPUs \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)  \n",
    "    \n",
    "# Pass the model parameters to the GPU.\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference model\n",
    "# test_sentence = 'you can get a complete overview of all applications delivered with mss wda in the sap library for sap erp on sap help portal at sap erp enhancement packages erp central component shared services manager self service manager self service wda applications'\n",
    "# test_sentence = 'common object layer brim billing and revenue innovation management ccm cross catalog mapping sap cc sap convergent charging system sap ci sap convergent invoicing smt subscriber mapping table srt subscriber range table odi order distribution'\n",
    "# test_sentence = 'this article is related to hana'\n",
    "test_sentence = 'sap erp is the best erp'\n",
    "\n",
    "inference_sap_bert(test_sentence, model)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.p3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.4 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.4-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
