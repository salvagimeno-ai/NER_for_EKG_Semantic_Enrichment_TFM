{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Join-multiple-csv-files.ipynb\t     old_datasets\n",
      "'adjust sap_hana tokens.ipynb'\t     scw_01-23_sa_v5.csv\n",
      " delete_O_sentences_renumber.ipynb   scw_01-23_sa_v6.csv\n",
      " hve_scw_01_23_da.csv\t\t     scw_01_23_da.csv\n",
      " hve_scw_100_149_da.csv\t\t     scw_1-149_220-272_da.csv\n",
      " hve_scw_220_272_da.csv\t\t     scw_100_149_da.csv\n",
      " hve_scw_24-49_da.csv\t\t     scw_1_149_da.csv\n",
      " hve_scw_50_99_da.csv\t\t     scw_220_248_da.csv\n",
      " nhve_scw_01_23_da.csv\t\t     scw_220_272_da.csv\n",
      " nhve_scw_100_149_da.csv\t     scw_24-49_da.csv\n",
      " nhve_scw_220_272_da.csv\t     scw_250_272_da.csv\n",
      " nhve_scw_24-49_da.csv\t\t     scw_50_99_da.csv\n",
      " nhve_scw_50_99_da.csv\n"
     ]
    }
   ],
   "source": [
    "# BASE_FOLDER = \"corp_wiki_texts/ejecucion3/\"\n",
    "# BASE_FOLDER = \"corp_wiki_annotated/\"\n",
    "# BASE_FOLDER = \"training-datasets/\"\n",
    "# !ls = \"{BASE_FOLDER}\"\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import packages and set the working directory\n",
    "Change “/mydir” to your desired working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"corp_wiki_texts/ejecucion3/\")\n",
    "# os.chdir(\"corp_wiki_annotated/\")\n",
    "# os.chdir(\"training-datasets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Use glob to match the pattern ‘csv’\n",
    "Match the pattern (‘csv’) and save the list of file names in the ‘all_filenames’ variable. You can check out this link to learn more about regular expression matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "       263, 264, 265, 266, 267, 268, 269, 270, 271, 272])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_number = np.arange(250,273)\n",
    "file_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) add files by name string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) add files by name string\n",
    "all_filenames = []\n",
    "\n",
    "file_number = np.arange(250,273)\n",
    "\n",
    "for n in file_number:\n",
    "    file_name = \"corp-wiki-\"+str(n)+\"-annotated_sentences.csv\"\n",
    "    all_filenames.append(file_name)\n",
    "    \n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # b) add files specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hve_scw_01_23_da.csv',\n",
       " 'hve_scw_24-49_da.csv',\n",
       " 'hve_scw_50_99_da.csv',\n",
       " 'hve_scw_100_149_da.csv',\n",
       " 'hve_scw_220_272_da.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) add files specifically\n",
    "\n",
    "all_filenames = []\n",
    "\n",
    "# file_name = \"scw_01_23_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_24-49_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_50_99_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_100_149_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "\n",
    "# file_name = \"scw_1_149_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "# file_name = \"scw_220_272_da.csv\"\n",
    "# all_filenames.append(file_name)\n",
    "\n",
    "file_name = 'hve_scw_01_23_da.csv'\n",
    "all_filenames.append(file_name)\n",
    "file_name = 'hve_scw_24-49_da.csv'\n",
    "all_filenames.append(file_name)\n",
    "file_name = 'hve_scw_50_99_da.csv'\n",
    "all_filenames.append(file_name)\n",
    "file_name = 'hve_scw_100_149_da.csv'\n",
    "all_filenames.append(file_name)\n",
    "file_name = 'hve_scw_220_272_da.csv'\n",
    "all_filenames.append(file_name)\n",
    "    \n",
    "all_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combine all files in the list and export as CSV\n",
    "Use pandas to concatenate all files in the list and export as CSV. The output file is named “combined_csv.csv” located in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "\n",
    "# #export to csv\n",
    "# TARGET_FOLDER = 'training-datasets/'\n",
    "# filename = 'scw_24_49_da.csv'\n",
    "# pathfilename = str(TARGET_FOLDER+filename)\n",
    "\n",
    "# combined_csv.to_csv(pathfilename, index=False, encoding='utf-8-sig')\n",
    "# combined_csv.to_csv( \"scw_24_49_da.csv\", index=False, encoding='utf-8-sig')\n",
    "combined_csv.to_csv('scw_hve_1-149_220-272_da.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding = ‘utf-8-sig’ is added to overcome the issue when exporting ‘Non-English’ languages.\n",
    "\n",
    "And…it’s done!\n",
    "\n",
    "This article was inspired by my actual everyday problem, and the coding structure is from a discussion on stackoverflow. The completed script for this how-to is documented on GitHub.\n",
    "\n",
    "Thank you for reading. Please give it a try, have fun and let me know your feedback!\n",
    "\n",
    "If you like what I did, consider following me on GitHub, Medium, and Twitter. Make sure to star it on GitHub :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
